、# 财务报表 RAG 系统架构设计

本文档细化财务报表分析项目的整体架构，重点描述“抽取 ➝ 索引 ➝ 检索 ➝ 分析”全链路，并给出可选的技术选型、模块职责与数据规范，方便后续实现与迭代。

## 1. 系统分层概览

```
┌───────────────┐      ┌─────────────┐      ┌──────────────┐      ┌──────────────┐
│ Ingestion 层  │ ───▶ │ Indexing 层 │ ───▶ │ Retrieval 层 │ ───▶ │ LLM 分析层    │
└───────────────┘      └─────────────┘      └──────────────┘      └──────────────┘
        │                     │                     │                     │
        ▼                     ▼                     ▼                     ▼
 ┌───────────────┐   ┌────────────────┐   ┌───────────────────┐   ┌────────────────┐
 │ 数据存储与缓存 │   │ Embeddings 存储 │   │ Prompt / Tooling │   │ 输出与验证        │
 └───────────────┘   └────────────────┘   └───────────────────┘   └────────────────┘
```

- **Ingestion 层**：完成 PDF 上传、解析、清洗、结构化；保证可重复、可追溯。
- **Indexing 层**：对抽取的文本/表格进行切片、生成向量嵌入，写入向量数据库。
- **Retrieval 层**：根据用户问题检索片段，组装上下文，并协调工具调用。
- **LLM 分析层**：执行提示模板、链式推理、工具调用，返回带引用的分析结果。
- **数据存储**：包含原文件、抽取结果、索引数据、查询日志。

## 2. Ingestion 层设计

### 2.1 功能要点
- PDF 上传后进入队列（可选消息系统：RabbitMQ、Redis Stream）。
- 抽取管线分离文本、表格、图片/OCR，输出统一的结构化格式。
- 记录元数据：文件名、年份、报告类型（10-K、年报、季报）、币种、语言。

### 2.2 库与工具
- **文本与布局**：`pdfplumber` + `pdfminer.six`（补充）
- **表格解析**：`camelot-py`（Lattice/Stream 双模式）或 `tabula-py`
- **OCR 兜底**：`pdf2image` + `pytesseract` / `PaddleOCR`
- **版面识别（可选）**：`layoutparser` + `detectron2`
- **综合框架**：`unstructured` 提供统一的块级输出，需定制化后处理

### 2.3 数据结构示例
```json
{
  "document_id": "abc123",
  "metadata": {
    "source_path": "uploads/2022-ACME-10K.pdf",
    "fiscal_year": 2022,
    "report_type": "10-K",
    "language": "zh-CN"
  },
  "sections": [
    {
      "section_id": "sec_mda",
      "title": "管理层讨论与分析",
      "page_start": 45,
      "page_end": 68,
      "chunks": [
        {
          "chunk_id": "sec_mda_001",
          "text": "...",
          "page": 45,
          "bbox": [x0, y0, x1, y1],
          "labels": ["paragraph", "narrative"]
        }
      ]
    }
  ],
  "tables": [
    {
      "table_id": "tbl_inc_statement",
      "title": "合并损益表",
      "page": 52,
      "unit": "百万人民币",
      "data": [
        {"metric": "营业收入", "2021": 1200, "2020": 980, "2019": 870}
      ],
      "raw_html": "<table>...</table>"
    }
  ]
}
```

### 2.4 质量控制
- **自动校验**：检查货币单位、千分符、负号是否正确；对表格执行 schema 校验。
- **人工抽样**：定期抽查段落与原 PDF 是否一致。
- **日志审计**：保留抽取流程日志和失败案例以便重试。

## 3. Indexing 层设计

### 3.1 切片策略
- **段落切片**：按章节与自然段合并，控制 token 数量（推荐 256-512 tokens）。
- **滑动窗口**：对长段落使用 `chunk_size` + `chunk_overlap`（如 400 + 80），避免上下文割裂。
- **表格处理**：将表格序列化为描述性文本或列式 JSON，必要时拆分为“指标 + 数值”对。
- **元数据保留**：每个 chunk 记录 `document_id`、`section_id`、`page`、`labels`、`table_id` 等，便于检索过滤。

可暴露配置项：
```yaml
chunk_size: 400
chunk_overlap: 80
combine_by_section: true
separate_tables: true
```

### 3.2 嵌入生成
- **Embedding 模型**：OpenAI `text-embedding-3-large`、`bge-large-zh`（中文）或 `Instructor-xl`。
- **批处理**：异步/批量请求，记录失败重试。
- **向量存储**：FAISS（本地）、Milvus、Pinecone、Weaviate 等，根据部署环境选择。

### 3.3 索引维护
- **版本控制**：对每次重建或追加索引生成索引版本号。
- **增量更新**：新文档或更新文档只重新索引受影响 chunk。
- **冷热分层**：历史报告向冷存储转移，但仍保留检索能力。

## 4. Retrieval 层设计

### 4.1 查询流程
1. 接收用户问题，标准化（语言检测、术语扩展）。
2. 生成查询向量，调用向量库检索 Top K（常见 5-10）。
3. 根据元数据做二次筛选：按年份/报告类型过滤，排除低置信度 chunk。
4. 对结果进行重排序（可选）：
   - 语义重排序（Cross-Encoder，如 `bge-reranker-large`)
   - 基于规则的加权（优先最新年份、匹配指标名等）
5. 组装上下文：构造结构化上下文（文本 + 表格数据 + 引用元信息）。

### 4.2 工具调用与函数
- **指标计算器**：接收指标名、年份，返回值及同比/环比。
- **表格查找器**：按表格标签快速获取原始表格数据。
- **知识图谱接口**（可选）：用于查询实体关系、风险标签等。

### 4.3 日志与监控
- 记录每次查询的检索片段、得分、最终答案。
- 抽样评估命中率（Recall@K）、最终回答质量。
- 建立告警：检索结果为空或得分过低时触发兜底策略（如回退到关键字查询）。

## 5. LLM 分析层

### 5.1 Prompt 结构
- **系统提示**：定义角色、输出格式、引用要求。
- **上下文注入**：插入检索到的段落和表格，注明来源。
- **思维链模板**：鼓励“先列步骤，再得结论”的回答顺序。

### 5.2 工具/函数调用
- 利用 OpenAI Function Calling / 自建工具接口让模型触发指标计算、表格筛选。
- 对复杂计算或长表格，避免直接塞入上下文，改用工具返回聚合结果。

### 5.3 输出规范
- 包含结论、关键数据点、参考来源（页码/表格 ID）。
- 提供未决问题或需人工确认的事项。

## 6. 存储与数据治理

| 存储类型 | 建议技术 | 内容 |
| -------- | -------- | ---- |
| 对象存储 | S3 / MinIO / 本地文件系统 | 原始 PDF、抽取产物 |
| 文本数据库 | PostgreSQL / MongoDB | 结构化抽取结果、元数据 |
| 向量库 | FAISS / Milvus / Pinecone | Chunk 向量 |
| 日志与监控 | ELK / OpenSearch / 数据仓库 | 抽取、检索、回答日志 |

- 提供审计 trail：记录每次分析引用了哪些源数据。
- 设计数据保留策略，满足合规要求。

## 7. 部署与扩展

- **服务划分**：
  1. `ingestion-service`：负责抽取与数据持久化，可异步处理。
  2. `indexing-service`：监听抽取结果，生成嵌入并写入向量库。
  3. `query-service`：暴露 API，整合检索、工具调用、LLM 调用。
  4. `frontend / notebook`：用户交互界面。
- **任务编排**：使用 Celery / Dramatiq 实现异步任务；或借助 Airflow 做批处理流水线。
- **横向扩展**：向量库与 LLM 服务分离，便于独立扩容。
- **缓存策略**：对常见问题/指标设置缓存，减少重复检索与调用成本。

## 8. 开发路线建议

1. **MVP 阶段**
   - 选定几份样本财报。
   - 实现 `pdfplumber` + `camelot` 的抽取 pipeline。
   - 使用单一向量库（如 FAISS）构建索引，完成基本检索 + 回答。
   - CLI 或 Notebook 形式验证核心流程。

2. **增强阶段**
   - 加入 OCR 兜底、版面识别，提升抽取质量。
   - 引入重排序器、指标计算工具。
   - 搭建 Web API 与简单前端。

3. **生产化阶段**
   - 完善监控、日志与测试。
   - 支持权限控制、多租户。
   - 优化性能与成本（批量嵌入、缓存、索引压缩）。

## 9. 下一步

- 根据样本财报测试抽取模块，统计错误类型。
- 明确向量库部署方式（本地 vs 托管）。
- 定义评价指标：检索命中率、回答准确率、计算正确率。
- 制定 Prompt 规范与回答模板，确保输出一致性。

后续可以在此文档基础上补充具体实现细节与代码链接，并维护工程进度。

